# -*- coding: utf-8 -*-
"""tf_autoencoder_pca_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Iu6vwRzK_mBHpWAm99-DY43XnpRBxVY4

# Linear Autoencoder for PCA

[Prashant Brahmbhatt](www.github.com/hashbanger)

____

To reduce a 30 dimensional data set for classification into a 2-dimensional dataset! Also need to verify if we still have the same level of class separation in the dimensionality reduction

### Imports
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""Using pandas to read in the csv file called anonymized_data.csv . It contains 500 rows and 30 columns of anonymized data along with 1 last column with a classification label, where the columns have been renamed to 4 letter codes"""

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv("drive/My Drive/Colab Notebooks/anonymized_data.csv")

df.head()

df.info()

"""### Scaling the Data

Scaling the data with a MinMaxScaler.
"""

X_full = df.iloc[:,:-1]

y_full = df.iloc[:, -1]

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()

X_full_scaled = scaler.fit_transform(X_full)

"""# The Linear Autoencoder

Importing tensorflow and fully_connected layers
"""

import tensorflow as tf
from tensorflow.contrib.layers import fully_connected

"""Filling out the number of inputs to fit the dimensions of the data set and setting the hidden number of units to be 2. Also setting the number of outputs to match the number of inputs. Then choosing a learning_rate value."""

X_full.shape

num_inputs = 30
num_hidden = 2 
num_outputs = 30 

learning_rate = 0.01

"""### Placeholder

Creating a placeholder for the data called X
"""

X = tf.placeholder(tf.float32, shape = [None, 30])

"""### Layers

Creating the hidden layer and the output layers using the [fully_connected](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/fully_connected) function.
"""

hidden1 = fully_connected(X, num_hidden, activation_fn = None)
output = fully_connected(hidden1, num_outputs, activation_fn = None)

"""### Loss Function

Creating a Mean Squared Error loss function.
"""

loss = tf.reduce_mean(tf.square(output - X))

"""### Optimizer

Creating an AdamOptimizer designed to minimize the previous loss function.
"""

optimizer = tf.train.AdamOptimizer(learning_rate)
train = optimizer.minimize(loss)

"""### Init

Creating an instance of a global variable intializer.
"""

init = tf.global_variables_initializer()

"""## Running the Session

Now creating a Tensorflow session that runs the optimizer for at least 1000 steps.
"""

num_steps = 1000

with tf.Session() as sess:
    
    sess.run(init)
    
    for step in range(1000):
        sess.run(train, feed_dict = {X: X_full_scaled})
        
    #now asking for the hidden layer output
    output_2d = hidden1.eval(feed_dict = {X: X_full_scaled})

"""Confirming that our output is now 2 dimensional along the previous axis of 30 features."""

output_2d.shape

"""Now plotting out the reduced dimensional representation of the data."""

plt.scatter(output_2d[:, 0], output_2d[:, 1], c = y_full)

"""So we have successfully reduced the dimensions to only 2 from 30.

## de nada!
"""