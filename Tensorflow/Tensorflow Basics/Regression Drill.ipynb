{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>housingMedianAge</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>52.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalRooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1447.7500</td>\n",
       "      <td>2127.0000</td>\n",
       "      <td>3148.00000</td>\n",
       "      <td>39320.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalBedrooms</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.0000</td>\n",
       "      <td>435.0000</td>\n",
       "      <td>647.00000</td>\n",
       "      <td>6445.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>787.0000</td>\n",
       "      <td>1166.0000</td>\n",
       "      <td>1725.00000</td>\n",
       "      <td>35682.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>households</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>280.0000</td>\n",
       "      <td>409.0000</td>\n",
       "      <td>605.00000</td>\n",
       "      <td>6082.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianIncome</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>0.4999</td>\n",
       "      <td>2.5634</td>\n",
       "      <td>3.5348</td>\n",
       "      <td>4.74325</td>\n",
       "      <td>15.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medianHouseValue</th>\n",
       "      <td>20640.0</td>\n",
       "      <td>206855.816909</td>\n",
       "      <td>115395.615874</td>\n",
       "      <td>14999.0000</td>\n",
       "      <td>119600.0000</td>\n",
       "      <td>179700.0000</td>\n",
       "      <td>264725.00000</td>\n",
       "      <td>500001.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count           mean            std         min  \\\n",
       "housingMedianAge  20640.0      28.639486      12.585558      1.0000   \n",
       "totalRooms        20640.0    2635.763081    2181.615252      2.0000   \n",
       "totalBedrooms     20640.0     537.898014     421.247906      1.0000   \n",
       "population        20640.0    1425.476744    1132.462122      3.0000   \n",
       "households        20640.0     499.539680     382.329753      1.0000   \n",
       "medianIncome      20640.0       3.870671       1.899822      0.4999   \n",
       "medianHouseValue  20640.0  206855.816909  115395.615874  14999.0000   \n",
       "\n",
       "                          25%          50%           75%          max  \n",
       "housingMedianAge      18.0000      29.0000      37.00000      52.0000  \n",
       "totalRooms          1447.7500    2127.0000    3148.00000   39320.0000  \n",
       "totalBedrooms        295.0000     435.0000     647.00000    6445.0000  \n",
       "population           787.0000    1166.0000    1725.00000   35682.0000  \n",
       "households           280.0000     409.0000     605.00000    6082.0000  \n",
       "medianIncome           2.5634       3.5348       4.74325      15.0001  \n",
       "medianHouseValue  119600.0000  179700.0000  264725.00000  500001.0000  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_data = housing.drop('medianHouseValue', axis = 1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  \n",
       "0        8.3252  \n",
       "1        8.3014  \n",
       "2        7.2574  \n",
       "3        5.6431  \n",
       "4        3.8462  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = housing['medianHouseValue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_true, test_size = 0.3, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc =MinMaxScaler(feature_range= (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(sc.fit_transform(X_train), columns= X_train.columns, index= X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(sc.fit_transform(X_test), columns= X_test.columns, index= X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['housingMedianAge', 'totalRooms', 'totalBedrooms', 'population',\n",
       "       'households', 'medianIncome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "All the features are **Continuous Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "housingAge = tf.feature_column.numeric_column('housingMedianAge')\n",
    "totalRooms = tf.feature_column.numeric_column('totalRooms')\n",
    "totalBedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "population = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "medianIncome = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_columns = [housingAge, totalBedrooms, totalRooms, population, households, medianIncome]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(X_train, y_train, batch_size= 10, num_epochs= 1000, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\prash\\AppData\\Local\\Temp\\tmpjbvo2fl4\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_num_ps_replicas': 0, '_task_id': 0, '_keep_checkpoint_max': 5, '_master': '', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027BB77A2588>, '_save_checkpoints_secs': 600, '_save_summary_steps': 100, '_model_dir': 'C:\\\\Users\\\\prash\\\\AppData\\\\Local\\\\Temp\\\\tmpjbvo2fl4', '_tf_random_seed': None, '_log_step_count_steps': 100, '_global_id_in_cluster': 0, '_session_config': None, '_task_type': 'worker', '_service': None, '_save_checkpoints_steps': None, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNRegressor(hidden_units= [10,10,10], feature_columns= feat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\prash\\AppData\\Local\\Temp\\tmpjbvo2fl4\\model.ckpt.\n",
      "INFO:tensorflow:step = 0, loss = 592823840000.0\n",
      "INFO:tensorflow:global_step/sec: 56.2485\n",
      "INFO:tensorflow:step = 100, loss = 452586300000.0 (1.778 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.677\n",
      "INFO:tensorflow:step = 200, loss = 749598900000.0 (0.725 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.721\n",
      "INFO:tensorflow:step = 300, loss = 346347440000.0 (0.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.034\n",
      "INFO:tensorflow:step = 400, loss = 305627400000.0 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.47\n",
      "INFO:tensorflow:step = 500, loss = 223672810000.0 (0.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 155.556\n",
      "INFO:tensorflow:step = 600, loss = 400636970000.0 (0.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.291\n",
      "INFO:tensorflow:step = 700, loss = 122162495000.0 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.892\n",
      "INFO:tensorflow:step = 800, loss = 262183010000.0 (0.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.935\n",
      "INFO:tensorflow:step = 900, loss = 185443190000.0 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.337\n",
      "INFO:tensorflow:step = 1000, loss = 133109320000.0 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.355\n",
      "INFO:tensorflow:step = 1100, loss = 70303950000.0 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.805\n",
      "INFO:tensorflow:step = 1200, loss = 143844280000.0 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.788\n",
      "INFO:tensorflow:step = 1300, loss = 93032590000.0 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.981\n",
      "INFO:tensorflow:step = 1400, loss = 153584520000.0 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.516\n",
      "INFO:tensorflow:step = 1500, loss = 109895050000.0 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.861\n",
      "INFO:tensorflow:step = 1600, loss = 160779160000.0 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.956\n",
      "INFO:tensorflow:step = 1700, loss = 108353225000.0 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.35\n",
      "INFO:tensorflow:step = 1800, loss = 152112040000.0 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.536\n",
      "INFO:tensorflow:step = 1900, loss = 138119760000.0 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.095\n",
      "INFO:tensorflow:step = 2000, loss = 138824650000.0 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.073\n",
      "INFO:tensorflow:step = 2100, loss = 143014280000.0 (0.649 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.627\n",
      "INFO:tensorflow:step = 2200, loss = 126456860000.0 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.378\n",
      "INFO:tensorflow:step = 2300, loss = 155963820000.0 (0.615 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.215\n",
      "INFO:tensorflow:step = 2400, loss = 55239460000.0 (0.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.571\n",
      "INFO:tensorflow:step = 2500, loss = 81526620000.0 (0.637 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.688\n",
      "INFO:tensorflow:step = 2600, loss = 89559980000.0 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.772\n",
      "INFO:tensorflow:step = 2700, loss = 113373470000.0 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.843\n",
      "INFO:tensorflow:step = 2800, loss = 50797027000.0 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.903\n",
      "INFO:tensorflow:step = 2900, loss = 60452405000.0 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.604\n",
      "INFO:tensorflow:step = 3000, loss = 62816550000.0 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.758\n",
      "INFO:tensorflow:step = 3100, loss = 141377100000.0 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.842\n",
      "INFO:tensorflow:step = 3200, loss = 163042820000.0 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.803\n",
      "INFO:tensorflow:step = 3300, loss = 65772913000.0 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.779\n",
      "INFO:tensorflow:step = 3400, loss = 71352600000.0 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.171\n",
      "INFO:tensorflow:step = 3500, loss = 66784215000.0 (0.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.432\n",
      "INFO:tensorflow:step = 3600, loss = 96134820000.0 (0.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.87\n",
      "INFO:tensorflow:step = 3700, loss = 227140120000.0 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.682\n",
      "INFO:tensorflow:step = 3800, loss = 71414130000.0 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.32\n",
      "INFO:tensorflow:step = 3900, loss = 177564980000.0 (0.792 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.496\n",
      "INFO:tensorflow:step = 4000, loss = 78166520000.0 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.386\n",
      "INFO:tensorflow:step = 4100, loss = 62690853000.0 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.067\n",
      "INFO:tensorflow:step = 4200, loss = 105042050000.0 (0.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.151\n",
      "INFO:tensorflow:step = 4300, loss = 81244700000.0 (0.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.674\n",
      "INFO:tensorflow:step = 4400, loss = 79842650000.0 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.994\n",
      "INFO:tensorflow:step = 4500, loss = 139138140000.0 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.64\n",
      "INFO:tensorflow:step = 4600, loss = 184431400000.0 (0.705 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.611\n",
      "INFO:tensorflow:step = 4700, loss = 38117910000.0 (0.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.007\n",
      "INFO:tensorflow:step = 4800, loss = 123039240000.0 (0.667 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.27\n",
      "INFO:tensorflow:step = 4900, loss = 89323150000.0 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.331\n",
      "INFO:tensorflow:step = 5000, loss = 53803782000.0 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.801\n",
      "INFO:tensorflow:step = 5100, loss = 159992070000.0 (0.636 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.357\n",
      "INFO:tensorflow:step = 5200, loss = 108969480000.0 (0.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.534\n",
      "INFO:tensorflow:step = 5300, loss = 90682876000.0 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.758\n",
      "INFO:tensorflow:step = 5400, loss = 209420520000.0 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.507\n",
      "INFO:tensorflow:step = 5500, loss = 103865760000.0 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.74\n",
      "INFO:tensorflow:step = 5600, loss = 55679762000.0 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.954\n",
      "INFO:tensorflow:step = 5700, loss = 123423056000.0 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.565\n",
      "INFO:tensorflow:step = 5800, loss = 51666764000.0 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.763\n",
      "INFO:tensorflow:step = 5900, loss = 51589816000.0 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.769\n",
      "INFO:tensorflow:step = 6000, loss = 102479680000.0 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.992\n",
      "INFO:tensorflow:step = 6100, loss = 75262660000.0 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.813\n",
      "INFO:tensorflow:step = 6200, loss = 58901963000.0 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.178\n",
      "INFO:tensorflow:step = 6300, loss = 50531344000.0 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.472\n",
      "INFO:tensorflow:step = 6400, loss = 55507292000.0 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.462\n",
      "INFO:tensorflow:step = 6500, loss = 99589240000.0 (0.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.899\n",
      "INFO:tensorflow:step = 6600, loss = 47639530000.0 (0.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.56\n",
      "INFO:tensorflow:step = 6700, loss = 44358455000.0 (0.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.695\n",
      "INFO:tensorflow:step = 6800, loss = 99712320000.0 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.771\n",
      "INFO:tensorflow:step = 6900, loss = 64003686000.0 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.047\n",
      "INFO:tensorflow:step = 7000, loss = 120748510000.0 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.446\n",
      "INFO:tensorflow:step = 7100, loss = 161657820000.0 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.504\n",
      "INFO:tensorflow:step = 7200, loss = 65342562000.0 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.762\n",
      "INFO:tensorflow:step = 7300, loss = 18928095000.0 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.284\n",
      "INFO:tensorflow:step = 7400, loss = 76539360000.0 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.067\n",
      "INFO:tensorflow:step = 7500, loss = 51921027000.0 (0.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.977\n",
      "INFO:tensorflow:step = 7600, loss = 97750520000.0 (0.559 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 182.352\n",
      "INFO:tensorflow:step = 7700, loss = 70513090000.0 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.714\n",
      "INFO:tensorflow:step = 7800, loss = 114337120000.0 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.392\n",
      "INFO:tensorflow:step = 7900, loss = 70231790000.0 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.982\n",
      "INFO:tensorflow:step = 8000, loss = 106731630000.0 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.245\n",
      "INFO:tensorflow:step = 8100, loss = 52576256000.0 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.069\n",
      "INFO:tensorflow:step = 8200, loss = 89418840000.0 (0.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.96\n",
      "INFO:tensorflow:step = 8300, loss = 55530082000.0 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.991\n",
      "INFO:tensorflow:step = 8400, loss = 50860913000.0 (0.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.273\n",
      "INFO:tensorflow:step = 8500, loss = 62489764000.0 (0.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.799\n",
      "INFO:tensorflow:step = 8600, loss = 63414840000.0 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.319\n",
      "INFO:tensorflow:step = 8700, loss = 84598300000.0 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.768\n",
      "INFO:tensorflow:step = 8800, loss = 129158120000.0 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.749\n",
      "INFO:tensorflow:step = 8900, loss = 69466280000.0 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.663\n",
      "INFO:tensorflow:step = 9000, loss = 92773810000.0 (0.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.88\n",
      "INFO:tensorflow:step = 9100, loss = 133078430000.0 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.797\n",
      "INFO:tensorflow:step = 9200, loss = 160263270000.0 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.726\n",
      "INFO:tensorflow:step = 9300, loss = 120500100000.0 (0.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.395\n",
      "INFO:tensorflow:step = 9400, loss = 142339820000.0 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.814\n",
      "INFO:tensorflow:step = 9500, loss = 120798040000.0 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.094\n",
      "INFO:tensorflow:step = 9600, loss = 106500470000.0 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.475\n",
      "INFO:tensorflow:step = 9700, loss = 209465590000.0 (0.560 sec)\n",
      "INFO:tensorflow:global_step/sec: 159.228\n",
      "INFO:tensorflow:step = 9800, loss = 85295290000.0 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.868\n",
      "INFO:tensorflow:step = 9900, loss = 156903150000.0 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.012\n",
      "INFO:tensorflow:step = 10000, loss = 261873040000.0 (0.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.654\n",
      "INFO:tensorflow:step = 10100, loss = 123421970000.0 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 171.309\n",
      "INFO:tensorflow:step = 10200, loss = 71857710000.0 (0.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.77\n",
      "INFO:tensorflow:step = 10300, loss = 56113080000.0 (0.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.541\n",
      "INFO:tensorflow:step = 10400, loss = 132466160000.0 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.652\n",
      "INFO:tensorflow:step = 10500, loss = 78320800000.0 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.445\n",
      "INFO:tensorflow:step = 10600, loss = 105442960000.0 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.446\n",
      "INFO:tensorflow:step = 10700, loss = 65581830000.0 (0.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.555\n",
      "INFO:tensorflow:step = 10800, loss = 68609085000.0 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.48\n",
      "INFO:tensorflow:step = 10900, loss = 44177870000.0 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.604\n",
      "INFO:tensorflow:step = 11000, loss = 81803395000.0 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.912\n",
      "INFO:tensorflow:step = 11100, loss = 78600010000.0 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.522\n",
      "INFO:tensorflow:step = 11200, loss = 178560960000.0 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.469\n",
      "INFO:tensorflow:step = 11300, loss = 160542000000.0 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.146\n",
      "INFO:tensorflow:step = 11400, loss = 148007390000.0 (0.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 150.14\n",
      "INFO:tensorflow:step = 11500, loss = 47975620000.0 (0.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.596\n",
      "INFO:tensorflow:step = 11600, loss = 101013440000.0 (0.641 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.094\n",
      "INFO:tensorflow:step = 11700, loss = 159490750000.0 (0.752 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.979\n",
      "INFO:tensorflow:step = 11800, loss = 147389240000.0 (0.588 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.747\n",
      "INFO:tensorflow:step = 11900, loss = 168828630000.0 (0.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.703\n",
      "INFO:tensorflow:step = 12000, loss = 76116040000.0 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.404\n",
      "INFO:tensorflow:step = 12100, loss = 62365536000.0 (0.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.876\n",
      "INFO:tensorflow:step = 12200, loss = 55413030000.0 (0.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.554\n",
      "INFO:tensorflow:step = 12300, loss = 131645750000.0 (0.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.867\n",
      "INFO:tensorflow:step = 12400, loss = 63599313000.0 (0.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.005\n",
      "INFO:tensorflow:step = 12500, loss = 270096000000.0 (0.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.931\n",
      "INFO:tensorflow:step = 12600, loss = 32963514000.0 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.752\n",
      "INFO:tensorflow:step = 12700, loss = 82563540000.0 (0.569 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.121\n",
      "INFO:tensorflow:step = 12800, loss = 38085394000.0 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.562\n",
      "INFO:tensorflow:step = 12900, loss = 66726138000.0 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.316\n",
      "INFO:tensorflow:step = 13000, loss = 145380410000.0 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.367\n",
      "INFO:tensorflow:step = 13100, loss = 69567810000.0 (0.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 165.74\n",
      "INFO:tensorflow:step = 13200, loss = 143310240000.0 (0.603 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.516\n",
      "INFO:tensorflow:step = 13300, loss = 114163650000.0 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.843\n",
      "INFO:tensorflow:step = 13400, loss = 86648110000.0 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.197\n",
      "INFO:tensorflow:step = 13500, loss = 87494080000.0 (0.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.584\n",
      "INFO:tensorflow:step = 13600, loss = 85126816000.0 (0.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.21\n",
      "INFO:tensorflow:step = 13700, loss = 94430040000.0 (0.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.743\n",
      "INFO:tensorflow:step = 13800, loss = 61706867000.0 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.782\n",
      "INFO:tensorflow:step = 13900, loss = 106903940000.0 (0.698 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.539\n",
      "INFO:tensorflow:step = 14000, loss = 145479250000.0 (0.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.181\n",
      "INFO:tensorflow:step = 14100, loss = 110777590000.0 (0.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.449\n",
      "INFO:tensorflow:step = 14200, loss = 116272460000.0 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 172.957\n",
      "INFO:tensorflow:step = 14300, loss = 183982370000.0 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.585\n",
      "INFO:tensorflow:step = 14400, loss = 152879960000.0 (0.600 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.37\n",
      "INFO:tensorflow:step = 14500, loss = 74253255000.0 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.081\n",
      "INFO:tensorflow:step = 14600, loss = 92659925000.0 (0.621 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.629\n",
      "INFO:tensorflow:step = 14700, loss = 102877635000.0 (0.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.724\n",
      "INFO:tensorflow:step = 14800, loss = 71271850000.0 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.762\n",
      "INFO:tensorflow:step = 14900, loss = 99248950000.0 (0.569 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into C:\\Users\\prash\\AppData\\Local\\Temp\\tmpjbvo2fl4\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 102935355000.0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x27bb77a27b8>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.train(input_fn= input_func, steps = 15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input = tf.estimator.inputs.pandas_input_fn(X_test, batch_size= 10, num_epochs= 1, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dnn_model.predict(pred_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\prash\\AppData\\Local\\Temp\\tmpjbvo2fl4\\model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions = list(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in predictions:\n",
    "     pred.append(i['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121363.53396429213"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, pred)** 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
